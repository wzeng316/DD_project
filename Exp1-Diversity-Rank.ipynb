{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import yaml\n",
    "import tensorflow as tf\n",
    "from Exp_gain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vec(dimension):\n",
    "    return tf.Variable(tf.random_normal(dimension, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseRank(object):\n",
    "    \n",
    "    def __init__(self, lenepisode, nfeature, nhidden, lr):\n",
    "\n",
    "        self.len_episode = lenepisode\n",
    "        self.lr = lr\n",
    "        self.nhidden = nhidden\n",
    "        self.nfeature = nfeature\n",
    "\n",
    "        global DD_learning_rate, DD_reward, DD_current_state, DD_query, DD_perceive_docs, DD_candidate_docs, DD_all_docs, DD_Ndoc\n",
    "\n",
    "        global DD_query_state, DD_next_state, DD_score, DD_policy, DD_train_step, sess\n",
    "        \n",
    "        global cross_entropy,ep_split_train, DD_dynamic, score, policy\n",
    "\n",
    "        with tf.name_scope('input'):\n",
    "            DD_learning_rate = tf.placeholder(tf.float32)\n",
    "            DD_Ndoc = tf.placeholder(tf.int64)\n",
    "            DD_reward = tf.placeholder(tf.float32, None, name='reward')\n",
    "            DD_current_state = tf.placeholder(tf.float32, [None, nhidden], name='current_state')\n",
    "            DD_query = tf.placeholder(tf.float32, [None, nfeature], name='querys')\n",
    "            DD_perceive_docs = tf.placeholder(tf.float32, [None, nfeature], name='docs')\n",
    "            DD_candidate_docs = tf.placeholder(tf.float32, [None, nfeature], name='docs')\n",
    "            DD_all_docs = tf.placeholder(tf.float32, [None, nfeature], name='candidate_docs')\n",
    "\n",
    "        with tf.variable_scope('model_query') :\n",
    "            W_q = init_vec([nfeature, nhidden])\n",
    "            DD_query_state = tf.tanh(tf.matmul(DD_query, W_q))\n",
    "            \n",
    "\n",
    "        with tf.variable_scope('rnn1'):\n",
    "            cell = tf.contrib.rnn.GRUCell(nhidden)\n",
    "            ep_split = tf.split(DD_perceive_docs, 1, 0, 'split')\n",
    "            _, DD_next_state = tf.contrib.rnn.static_rnn(cell, ep_split, initial_state=DD_current_state, dtype=tf.float32)\n",
    "\n",
    "        with tf.variable_scope('policy'):\n",
    "            W = init_vec([nfeature, nhidden])\n",
    "            DD_score = tf.tanh(tf.matmul(DD_candidate_docs, tf.matmul(W, tf.transpose(DD_current_state))))\n",
    "            DD_policy = tf.nn.softmax(tf.transpose(DD_score))\n",
    "\n",
    "        \n",
    "        with tf.variable_scope('rnn1', reuse=True) as scope:\n",
    "            scope.reuse_variables()\n",
    "            cell = tf.contrib.rnn.GRUCell(nhidden)\n",
    " \n",
    "            ep_split_train = tf.split(DD_all_docs, 1000)               \n",
    "            DD_dynamic, _ = tf.contrib.rnn.static_rnn(cell, ep_split_train, initial_state=DD_query_state, dtype=tf.float32)\n",
    "            \n",
    "            cross_entropy = 0\n",
    "            for position in range(10):\n",
    "                score = tf.tanh(tf.matmul(DD_all_docs[position:], tf.matmul(W, tf.reshape(DD_dynamic[position][1], [nhidden, 1]))))\n",
    "                policy = tf.nn.softmax(tf.transpose(score))\n",
    "                cross_entropy += DD_reward[position] * tf.nn.sparse_softmax_cross_entropy_with_logits(logits=policy, labels=[0])\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        DD_train_step = tf.train.GradientDescentOptimizer(learning_rate=DD_learning_rate).minimize(cross_entropy)\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "    def gen_query_state(self, query):\n",
    "        query_vec = np.asarray(query).reshape([1, self.nfeature])\n",
    "        \n",
    "        state = sess.run(DD_query_state, feed_dict={DD_query: query_vec})\n",
    "        return state\n",
    "\n",
    "    def gen_next_state(self, current_state, perceive_docs):\n",
    "        current_state_vec = np.asarray(current_state).reshape([-1, self.nhidden])\n",
    "        perceive_docs_vec = np.asarray(perceive_docs).reshape([-1, self.nfeature])\n",
    "        \n",
    "        state = sess.run(DD_next_state, feed_dict={DD_current_state: current_state_vec, DD_perceive_docs: perceive_docs_vec} )\n",
    "        return state\n",
    "\n",
    "    def gen_score(self, current_state, candidate_docs):\n",
    "        current_state_vec = np.asarray(current_state).reshape([-1, self.nhidden])\n",
    "        candidate_docs_vec = np.asarray(candidate_docs).reshape([-1, self.nfeature])\n",
    "        \n",
    "        score = sess.run(DD_score, feed_dict={DD_current_state: current_state_vec, DD_candidate_docs: candidate_docs_vec})\n",
    "        return score\n",
    "\n",
    "    def gen_policy(self, current_state, candidate_docs):\n",
    "        current_state_vec = np.asarray(current_state).reshape([-1, self.nhidden])\n",
    "        candidate_docs_vec = np.asarray(candidate_docs).reshape([-1, self.nfeature])\n",
    "        \n",
    "        policy = sess.run(DD_policy, feed_dict={DD_current_state: current_state_vec, DD_candidate_docs: candidate_docs_vec})\n",
    "        return policy\n",
    "\n",
    "    def gen_episode_softmax(self, queryvec, docvec, docs):\n",
    "        current_state = self.gen_query_state(queryvec)\n",
    "\n",
    "        ndoc = len(docvec)\n",
    "\n",
    "        docd_id = docs[:]\n",
    "        n_candidate = ndoc\n",
    "\n",
    "        rank_list = []\n",
    "        for ite in range(min(ndoc, self.len_episode)):\n",
    "            policy = self.gen_policy(current_state, docvec)\n",
    "            action = np.random.choice(n_candidate, 1, p=policy[0])[0]           \n",
    "\n",
    "            current_state = self.gen_next_state(current_state, docvec[action])\n",
    "            \n",
    "            n_candidate = n_candidate - 1\n",
    "            rank_list.append(docd_id[action])\n",
    "            queryvec.append(docvec[action])\n",
    "            del docd_id[action]\n",
    "            del docvec[action]\n",
    "\n",
    "        return rank_list, queryvec + docvec\n",
    "\n",
    "    def gen_episode_greedy(self, queryvec, docvec, docs):\n",
    "\n",
    "        current_state = self.gen_query_state(queryvec)\n",
    "\n",
    "        Ndoc = len(docvec)\n",
    "        Nite = min(Ndoc, self.len_episode)\n",
    "\n",
    "        doc_id = docs[:]\n",
    "\n",
    "        rank_list = []\n",
    "        for ite in range(Nite):\n",
    "            score = self.gen_score(current_state, docvec)\n",
    "            action = np.argmax(score)\n",
    "\n",
    "            current_state = self.gen_next_state(current_state, docvec[action])\n",
    "            \n",
    "            rank_list.append(doc_id[action])\n",
    "            queryvec.append(docvec[action])\n",
    "            del doc_id[action]\n",
    "            del docvec[action]\n",
    "\n",
    "        return rank_list, queryvec + docvec\n",
    "\n",
    "    def test_model(self, querydocs, doc2vec, truth):\n",
    "        meanreward = 0\n",
    "        for query in querydocs.keys():\n",
    "            docs = querydocs[query][:]\n",
    "\n",
    "            ndoc = len(docs)\n",
    "            if ndoc < 2:\n",
    "                print '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', query\n",
    "                continue\n",
    "\n",
    "            querydocsvec = []\n",
    "            querydocsvec.append(doc2vec[query])\n",
    "            docsvec = []\n",
    "            for doc in docs:\n",
    "                docsvec.append(doc2vec[doc])\n",
    "\n",
    "            # gen episode\n",
    "            ranklist, _ = self.gen_episode_greedy(querydocsvec, docsvec, docs)\n",
    "\n",
    "            reward = alphaDCG_reward_per_query(ranklist, truth[query])\n",
    "            # print reward[0],\n",
    "            meanreward += reward[0]\n",
    "\n",
    "        print '\\n               ', meanreward, '\\n'\n",
    "\n",
    "    def train_model(self, querydocs, doc2vec, truth):\n",
    "        querylist = querydocs.keys()\n",
    "        train_data = {}\n",
    "        for query in querylist:\n",
    "            \n",
    "            docs = querydocs[query][:]\n",
    "\n",
    "            querydocsvec = []\n",
    "            querydocsvec.append(doc2vec[query])\n",
    "            docsvec = []\n",
    "            for doc in docs:\n",
    "                docsvec.append(doc2vec[doc])\n",
    "\n",
    "            ranklist, querydocvec = self.gen_episode_softmax(querydocsvec, docsvec, docs)\n",
    "            \n",
    "            # print ranklist\n",
    "            # print truth[query]\n",
    "            reward = alphaDCG_reward_per_query(ranklist, truth[query])\n",
    "            # print 'reward', reward[0]\n",
    "            train_data[query] = {'querydocvec': querydocvec, 'reward': reward}\n",
    "            \n",
    "        print 'optimize'\n",
    "        for query in querylist:\n",
    "            querydocvec = train_data[query]['querydocvec']\n",
    "            reward = train_data[query]['reward']\n",
    "            self.optimize_model(querydocvec, reward)\n",
    "\n",
    "    def optimize_model(self, querydocvec, reward):\n",
    "        ndoc = len(querydocvec)\n",
    "        # for i in range(len(reward)):\n",
    "        #     if reward[i] == 0:\n",
    "        #         continue\n",
    "        ndoc = len(querydocvec)-1\n",
    "        query_vec = np.asarray((querydocvec[0])).reshape([1, self.nfeature])\n",
    "        doc_vec = np.asarray(querydocvec[1:ndoc+1]).reshape([-1, self.nfeature])\n",
    "            \n",
    "        qqq=sess.run(score, feed_dict={DD_query: query_vec, DD_all_docs: doc_vec, DD_Ndoc : ndoc, DD_reward:reward, DD_learning_rate: self.lr})\n",
    "        print len(qqq)\n",
    "\n",
    "    def main(self, nite, querydocs, doc2vec, query_document_topic):\n",
    "        for ite in range(nite):\n",
    "            self.train_model(querydocs, doc2vec, query_document_topic)\n",
    "\n",
    "            if ite % 1 == 0:\n",
    "                self.test_model(querydocs, doc2vec, query_document_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1\nload 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 4\n"
     ]
    }
   ],
   "source": [
    "Truth = json.load(open('/users/zengwei/data/DD/ZW_JSON/Truth.json'))\n",
    "print 'load 1'\n",
    "QueryDocs = json.load(open('/users/zengwei/data/DD/ZW_JSON/MiniData_QueryDocs.json'))\n",
    "print 'load 3'\n",
    "Doc2Vec = json.load(open('/users/zengwei/data/DD/ZW_JSON/MiniData_200_50ite_Doc2Vec.json'))\n",
    "print 'load 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nfeature=200\n",
    "Nhidden = 10\n",
    "Lenepisode = 50\n",
    "lr=0.001\n",
    "\n",
    "model = DiverseRank(Lenepisode, Nfeature, Nhidden, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 1 of dimension 0 out of bounds.\n\t [[Node: rnn1_1/strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn1_1/rnn/rnn/gru_cell/add, rnn1_1/strided_slice_1/stack, rnn1_1/strided_slice_1/stack_1, rnn1_1/strided_slice_1/stack_2)]]\n\nCaused by op u'rnn1_1/strided_slice_1', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-2709faad4438>\", line 6, in <module>\n    model = DiverseRank(Lenepisode, Nfeature, Nhidden, lr)\n  File \"<ipython-input-3-6298f54f8650>\", line 50, in __init__\n    score = tf.tanh(tf.matmul(DD_all_docs[position:], tf.matmul(W, tf.reshape(DD_dynamic[position][1], [nhidden, 1]))))\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 501, in _SliceHelper\n    name=name)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 669, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3637, in strided_slice\n    shrink_axis_mask=shrink_axis_mask, name=name)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2583, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): slice index 1 of dimension 0 out of bounds.\n\t [[Node: rnn1_1/strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn1_1/rnn/rnn/gru_cell/add, rnn1_1/strided_slice_1/stack, rnn1_1/strided_slice_1/stack_1, rnn1_1/strided_slice_1/stack_2)]]\n",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-262ccfcee122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQueryDocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6298f54f8650>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, nite, querydocs, doc2vec, query_document_topic)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerydocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_document_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_document_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mite\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6298f54f8650>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, querydocs, doc2vec, truth)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mquerydocvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'querydocvec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerydocvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6298f54f8650>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(self, querydocvec, reward)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mdoc_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mndoc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mqqq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mDD_query\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDD_all_docs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDD_Ndoc\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mndoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDD_reward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDD_learning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqqq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 1 of dimension 0 out of bounds.\n\t [[Node: rnn1_1/strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn1_1/rnn/rnn/gru_cell/add, rnn1_1/strided_slice_1/stack, rnn1_1/strided_slice_1/stack_1, rnn1_1/strided_slice_1/stack_2)]]\n\nCaused by op u'rnn1_1/strided_slice_1', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-2709faad4438>\", line 6, in <module>\n    model = DiverseRank(Lenepisode, Nfeature, Nhidden, lr)\n  File \"<ipython-input-3-6298f54f8650>\", line 50, in __init__\n    score = tf.tanh(tf.matmul(DD_all_docs[position:], tf.matmul(W, tf.reshape(DD_dynamic[position][1], [nhidden, 1]))))\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 501, in _SliceHelper\n    name=name)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 669, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3637, in strided_slice\n    shrink_axis_mask=shrink_axis_mask, name=name)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2583, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): slice index 1 of dimension 0 out of bounds.\n\t [[Node: rnn1_1/strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn1_1/rnn/rnn/gru_cell/add, rnn1_1/strided_slice_1/stack, rnn1_1/strided_slice_1/stack_1, rnn1_1/strided_slice_1/stack_2)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.main(10000, QueryDocs, Doc2Vec, Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Doc2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split in module tensorflow.python.ops.array_ops:\n\nsplit(value, num_or_size_splits, axis=0, num=None, name='split')\n    Splits a tensor into sub tensors.\n    \n    If `num_or_size_splits` is an integer type, `num_split`, then splits `value`\n    along dimension `axis` into `num_split` smaller tensors.\n    Requires that `num_split` evenly divides `value.shape[axis]`.\n    \n    If `num_or_size_splits` is not an integer type, it is presumed to be a Tensor\n    `size_splits`, then splits `value` into `len(size_splits)` pieces. The shape\n    of the `i`-th piece has the same size as the `value` except along dimension\n    `axis` where the size is `size_splits[i]`.\n    \n    For example:\n    \n    ```python\n    # 'value' is a tensor with shape [5, 30]\n    # Split 'value' into 3 tensors with sizes [4, 15, 11] along dimension 1\n    split0, split1, split2 = tf.split(value, [4, 15, 11], 1)\n    tf.shape(split0) ==> [5, 4]\n    tf.shape(split1) ==> [5, 15]\n    tf.shape(split2) ==> [5, 11]\n    # Split 'value' into 3 tensors along dimension 1\n    split0, split1, split2 = tf.split(value, num_or_size_splits=3, axis=1)\n    tf.shape(split0) ==> [5, 10]\n    ```\n    \n    Args:\n      value: The `Tensor` to split.\n      num_or_size_splits: Either a 0-D integer `Tensor` indicating the number of\n        splits along split_dim or a 1-D integer `Tensor` integer tensor containing\n        the sizes of each output tensor along split_dim. If a scalar then it must\n        evenly divide `value.shape[axis]`; otherwise the sum of sizes along the\n        split dimension must match that of the `value`.\n      axis: A 0-D `int32` `Tensor`. The dimension along which to split.\n        Must be in the range `[-rank(value), rank(value))`. Defaults to 0.\n      num: Optional, used to specify the number of outputs when it cannot be\n        inferred from the shape of `size_splits`.\n      name: A name for the operation (optional).\n    \n    Returns:\n      if `num_or_size_splits` is a scalar returns `num_or_size_splits` `Tensor`\n      objects; if `num_or_size_splits` is a 1-D Tensor returns\n      `num_or_size_splits.get_shape[0]` `Tensor` objects resulting from splitting\n      `value`.\n    \n    Raises:\n      ValueError: If `num` is unspecified and cannot be inferred.\n\n"
     ]
    }
   ],
   "source": [
    "help(tf.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out tensors:\n[<tf.Tensor 'DynamicPartition_1:0' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:1' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:2' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:3' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:4' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:5' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:6' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:7' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:8' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:9' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:10' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:11' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:12' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:13' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:14' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:15' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:16' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:17' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:18' shape=(?, 2) dtype=int32>, <tf.Tensor 'DynamicPartition_1:19' shape=(?, 2) dtype=int32>]\n\ninput data:\n[[3 1]\n [6 9]\n [5 0]\n [4 1]\n [4 6]\n [1 4]\n [1 0]\n [7 9]\n [1 6]\n [3 8]\n [6 5]]\n\nsess.run result:\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "data.shape must start with partitions.shape, got data.shape = [11,2], partitions.shape = [13]\n\t [[Node: DynamicPartition_1 = DynamicPartition[T=DT_INT32, num_partitions=20, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_1_0_0, DynamicPartition_1/partitions)]]\n\nCaused by op u'DynamicPartition_1', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-1b63a68918f0>\", line 8, in <module>\n    out = tf.dynamic_partition(x, parts, 20)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 402, in dynamic_partition\n    num_partitions=num_partitions, name=name)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2583, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): data.shape must start with partitions.shape, got data.shape = [11,2], partitions.shape = [13]\n\t [[Node: DynamicPartition_1 = DynamicPartition[T=DT_INT32, num_partitions=20, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_1_0_0, DynamicPartition_1/partitions)]]\n",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1b63a68918f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'input data:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'sess.run result:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: data.shape must start with partitions.shape, got data.shape = [11,2], partitions.shape = [13]\n\t [[Node: DynamicPartition_1 = DynamicPartition[T=DT_INT32, num_partitions=20, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_1_0_0, DynamicPartition_1/partitions)]]\n\nCaused by op u'DynamicPartition_1', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-1b63a68918f0>\", line 8, in <module>\n    out = tf.dynamic_partition(x, parts, 20)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 402, in dynamic_partition\n    num_partitions=num_partitions, name=name)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2583, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/users/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): data.shape must start with partitions.shape, got data.shape = [11,2], partitions.shape = [13]\n\t [[Node: DynamicPartition_1 = DynamicPartition[T=DT_INT32, num_partitions=20, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_1_0_0, DynamicPartition_1/partitions)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.placeholder(tf.int32, shape=[None, 2])\n",
    "data = np.random.randint(10, size=(11,2))\n",
    "\n",
    "parts = range(13)\n",
    "out = tf.dynamic_partition(x, parts, 20)\n",
    "\n",
    "sess = tf.Session()\n",
    "print 'out tensors:\\n', out\n",
    "print\n",
    "print 'input data:\\n', data\n",
    "print\n",
    "print 'sess.run result:\\n', sess.run(out, {x: data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}