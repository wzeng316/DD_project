{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryDocs_Xia = json.load(open('/home/zengwei/data/XiaLong/query_doc.json'))\n",
    "\n",
    "QueryDocs={}\n",
    "for query in QueryDocs_Xia.keys():\n",
    "    \n",
    "    QueryDocs[query] = []\n",
    "    for doc in QueryDocs_Xia[query].keys():\n",
    "        QueryDocs[query].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QueryDocumentTopic = {}\n",
    "for query in QueryDocs_Xia.keys():\n",
    "    QueryDocumentTopic[query]={}\n",
    "    \n",
    "    for doc in QueryDocs_Xia[query].keys():\n",
    "        if len(QueryDocs_Xia[query][doc]) >0:\n",
    "            \n",
    "            QueryDocumentTopic[query][doc] = QueryDocs_Xia[query][doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Truth = {}\n",
    "for query in QueryDocs_Xia.keys():\n",
    "    Truth[query]=[]\n",
    "    Truth[query].append({})\n",
    "    \n",
    "    subtopic_list = []\n",
    "    for doc in QueryDocs_Xia[query].keys():\n",
    "        if len(QueryDocs_Xia[query][doc]) >0:\n",
    "            Truth[query][0][doc]= []\n",
    "            for subtopic in QueryDocs_Xia[query][doc]:\n",
    "                Truth[query][0][doc].append((subtopic, 1))\n",
    "                if subtopic not in subtopic_list:\n",
    "                    subtopic_list.append(subtopic)\n",
    "                \n",
    "    Truth[query].append(len(subtopic_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec_doc   = json.load(open('/home/zengwei/data/XiaLong/doc_representation.dat'))\n",
    "Doc2Vec_query = json.load(open('/home/zengwei/data/XiaLong/query_representation.dat'))\n",
    "Doc2Vec =dict (Doc2Vec_doc, **Doc2Vec_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Exp_gain import *\n",
    "\n",
    "def init_vec(dimension):\n",
    "    return tf.Variable(tf.random_normal(dimension, stddev=0.01))\n",
    "\n",
    "\n",
    "class DiverseRank(object):\n",
    "    def __init__(self, lenepisode, nfeature, nhidden, lr):\n",
    "\n",
    "        self.len_episode = lenepisode\n",
    "        self.lr = lr\n",
    "        \n",
    "        global learning_rate, query_docs, candidate_docs, score, policy, train_step, sess\n",
    "\n",
    "        with tf.name_scope('input'):\n",
    "            learning_rate = tf.placeholder(tf.float32)\n",
    "            query_docs = tf.placeholder(tf.float32, [None, nfeature], name='docs')\n",
    "            candidate_docs = tf.placeholder(tf.float32, [None, nfeature], name='candidate_docs')\n",
    "\n",
    "        cell = tf.contrib.rnn.GRUCell(nhidden)\n",
    "\n",
    "        with tf.name_scope('rnn'):\n",
    "            ep_split = tf.split(query_docs, 1, 0, 'split')\n",
    "            _, state = tf.contrib.rnn.static_rnn(cell, ep_split, dtype=tf.float32)\n",
    "\n",
    "        with tf.name_scope('policy'):\n",
    "            w = init_vec([nfeature, nhidden])\n",
    "            score = tf.tanh(tf.matmul(candidate_docs, tf.matmul(w, tf.reshape(state[-1], [nhidden, 1]))))\n",
    "            policy = tf.nn.softmax(tf.transpose(score))\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=policy, labels=[0])\n",
    "\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "\n",
    "\n",
    "    def gen_episode_softmax(self, queryvec, docvec, docs):\n",
    "        ndoc = len(docvec)\n",
    "        \n",
    "        docd_id = docs[:]\n",
    "        n_candidate = ndoc\n",
    "\n",
    "        rank_list = []\n",
    "        for ite in range(min(ndoc, self.len_episode)):\n",
    "            prob = sess.run(policy, feed_dict={query_docs: np.asanyarray(queryvec), candidate_docs: np.asanyarray(docvec)})\n",
    "            action = np.random.choice(n_candidate, 1, p=prob[0])[0]\n",
    "\n",
    "            n_candidate = n_candidate - 1\n",
    "            rank_list.append(docd_id[action])\n",
    "            queryvec.append(docvec[action])\n",
    "            del docd_id[action]\n",
    "            del docvec[action]\n",
    "\n",
    "        return rank_list, queryvec + docvec\n",
    "\n",
    "\n",
    "    def gen_episode_greedy(self, queryvec, docvec, docs):\n",
    "\n",
    "        Ndoc = len(docvec)\n",
    "        Nite = min(Ndoc, self.len_episode)\n",
    "        \n",
    "        doc_id = docs[:]\n",
    "        \n",
    "        \n",
    "        rank_list = []\n",
    "        for ite in range(Nite):\n",
    "            scores = sess.run(score, feed_dict={query_docs: np.asanyarray(queryvec), candidate_docs: np.asanyarray(docvec)})\n",
    "            action = np.argmax(scores)\n",
    "\n",
    "            rank_list.append(doc_id[action])\n",
    "            queryvec.append(docvec[action])\n",
    "            del doc_id[action]\n",
    "            del docvec[action]\n",
    "\n",
    "        return rank_list, queryvec + docvec\n",
    "\n",
    "\n",
    "    def test_model(self, querydocs, doc2vec, truth):\n",
    "        meanreward = 0\n",
    "        for query in querydocs.keys():\n",
    "            docs = querydocs[query][:]\n",
    "\n",
    "            ndoc = len(docs)\n",
    "            if ndoc < 2:\n",
    "                print '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', Query\n",
    "                continue\n",
    "\n",
    "            querydocsvec = []\n",
    "            querydocsvec.append(doc2vec[query])\n",
    "            docsvec = []\n",
    "            for doc in docs:\n",
    "                docsvec.append(doc2vec[doc])\n",
    "\n",
    "            # gen episode\n",
    "            ranklist, _= self.gen_episode_greedy(querydocsvec, docsvec, docs)\n",
    "            \n",
    "            reward = alphaDCG_get_reward(ranklist, truth[query])\n",
    "            # print reward[0],\n",
    "            meanreward += reward[0]\n",
    "\n",
    "        print '\\n               ', meanreward, '\\n'\n",
    "\n",
    "\n",
    "    def train_model(self, querydocs, doc2vec, truth):\n",
    "        querylist = querydocs.keys()\n",
    "        train_data = {}\n",
    "        for query in querylist:\n",
    "            docs = querydocs[query][:]\n",
    "\n",
    "            querydocsvec = []\n",
    "            querydocsvec.append(doc2vec[query])\n",
    "            docsvec = []\n",
    "            for doc in docs:\n",
    "                docsvec.append(doc2vec[doc])\n",
    "\n",
    "            ranklist, querydocvec = self.gen_episode_softmax(querydocsvec, docsvec, docs)\n",
    "            # print ranklist\n",
    "            # print truth[query]\n",
    "            reward = alphaDCG_get_reward(ranklist, truth[query])\n",
    "            # print 'reward', reward[0]\n",
    "            train_data[query] = { 'querydocvec': querydocvec, 'reward' : reward }\n",
    "\n",
    "        for query in querylist:\n",
    "            querydocvec = train_data[query]['querydocvec']\n",
    "            reward = train_data[query]['reward']\n",
    "            self.optimize_model(querydocvec, reward)\n",
    "\n",
    "\n",
    "    def optimize_model(self, querydocvec, reward):\n",
    "        ndoc = len(querydocvec)\n",
    "        for i in range(len(reward)):\n",
    "            if reward[i]==0:\n",
    "                continue\n",
    "            sess.run(train_step, feed_dict={query_docs: np.asanyarray(querydocvec[0:i + 1]),candidate_docs: np.asanyarray(querydocvec[i + 1:ndoc + 1]),learning_rate: self.lr * reward[i]})\n",
    "\n",
    "    def main(self, nite, querydocs, doc2vec, query_document_topic):\n",
    "        for ite in range(nite):\n",
    "            self.train_model(querydocs, doc2vec, query_document_topic)\n",
    "\n",
    "            if ite % 1 == 0:\n",
    "                self.test_model(querydocs, doc2vec, query_document_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n                248.268350163 \n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n                248.268350163 \n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n                248.268350163 \n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n                248.268350163 \n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n                248.268350163 \n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n                248.257276856 \n\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-22c2cdc2f1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQueryDocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-9042a93e7796>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, nite, querydocs, doc2vec, query_document_topic)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerydocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_document_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_document_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mite\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9042a93e7796>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, querydocs, doc2vec, truth)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mquerydocvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'querydocvec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9042a93e7796>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(self, querydocvec, reward)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mquery_docs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcandidate_docs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerydocvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mndoc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerydocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_document_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zengwei/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "Nfeature=100\n",
    "Nhidden = 10\n",
    "Lenepisode = 50\n",
    "lr=-0.0001\n",
    "\n",
    "model = DiverseRank(Lenepisode, Nfeature, Nhidden, lr)\n",
    "\n",
    "\n",
    "model.main(1000, QueryDocs, Doc2Vec, Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}