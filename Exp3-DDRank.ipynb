{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Exp_gain import *\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vec(dimension):\n",
    "    return tf.Variable(tf.random_normal(dimension, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDRank_1(object):\n",
    "    def __init__(self, time, n_feature, n_hidden, lr):\n",
    "\n",
    "        self.time = time\n",
    "        self.group_size = 5\n",
    "        self.lr = lr\n",
    "        self.top_n = 10\n",
    "\n",
    "        global learning_rate, query_docs, candidate_docs, score, policy, train_step, sess\n",
    "\n",
    "        with tf.name_scope('input'):\n",
    "            learning_rate = tf.placeholder(tf.float32)\n",
    "            query_docs = tf.placeholder(tf.float32, [None, n_feature], name='docs')\n",
    "            candidate_docs = tf.placeholder(tf.float32, [None, n_feature], name='candidate_docs')\n",
    "\n",
    "        cell = tf.contrib.rnn.GRUCell(n_hidden)\n",
    "\n",
    "        with tf.name_scope('rnn'):\n",
    "            ep_split = tf.split(query_docs, 1, 0, 'split')\n",
    "            _, state = tf.contrib.rnn.static_rnn(cell, ep_split, dtype=tf.float32)\n",
    "\n",
    "        with tf.name_scope('policy'):\n",
    "            w = init_vec([n_feature, n_hidden])\n",
    "            score = tf.tanh(tf.matmul(candidate_docs, tf.matmul(w, tf.reshape(state[-1], [n_hidden, 1]))))\n",
    "            policy = tf.nn.softmax(tf.transpose(score))\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=policy, labels=[0])\n",
    "\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "    def gen_group_episode_softmax(self, query_vec, doc_vec, docs, truth):\n",
    "        doc_id = docs[:]\n",
    "        input = query_vec\n",
    "\n",
    "        rank_list = []\n",
    "        relevance_feedback = []\n",
    "        for ite in range(self.time):\n",
    "            relevance_feedback.append([])\n",
    "            scores = sess.run(score, feed_dict={query_docs: np.asanyarray(input), candidate_docs: np.asanyarray(doc_vec)})\n",
    "            scores = np.asarray(scores)[:,0]\n",
    "\n",
    "            for i in range(self.group_size):\n",
    "                prob = np.exp(scores)/np.sum(np.exp(scores))\n",
    "                action = np.random.choice(len(prob), 1, p=prob)[0]\n",
    "\n",
    "                scores = np.delete(scores, action)\n",
    "                rank_list.append(doc_id[action])\n",
    "                query_vec.append(doc_vec[action])\n",
    "                if doc_id[action] in truth[0].keys():\n",
    "                    relevance_feedback[ite].append(doc_vec[action])\n",
    "\n",
    "                del doc_id[action]\n",
    "                del doc_vec[action]\n",
    "\n",
    "            # index = sorted(action_list)\n",
    "            # for i in range(len(index)):\n",
    "            #     del doc_id[index[i] - i]\n",
    "            #     del doc_vec[index[i] - i]\n",
    "\n",
    "            input = input + relevance_feedback[ite]\n",
    "\n",
    "        return rank_list, query_vec + doc_vec, relevance_feedback\n",
    "\n",
    "    def gen_group_episode_greedy(self, query_vec, doc_vec, docs, truth):\n",
    "        doc_id = docs[:]\n",
    "\n",
    "        rank_list = []\n",
    "        for ite in range(self.time):\n",
    "            scores = sess.run(score, feed_dict={query_docs: np.asanyarray(query_vec), candidate_docs: np.asanyarray(doc_vec)})\n",
    "\n",
    "            for i in range(self.group_size):\n",
    "                action = np.argmax(scores)\n",
    "\n",
    "                scores = np.delete(scores, action)\n",
    "                rank_list.append(doc_id[action])\n",
    "                if doc_id[action] in truth[0].keys():\n",
    "                    query_vec.append(doc_vec[action])\n",
    "                del doc_id[action]\n",
    "                del doc_vec[action]\n",
    "\n",
    "        return rank_list\n",
    "\n",
    "    def test_model(self, query_docs, doc2vec, truth):\n",
    "        mean_alphaNDCG = np.zeros(self.top_n)\n",
    "        n_query = len(query_docs.keys())\n",
    "\n",
    "        for query in query_docs.keys():\n",
    "            docs = query_docs[query][:]\n",
    "\n",
    "            n_doc = len(docs)\n",
    "            if n_doc < 2:\n",
    "                print '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', query\n",
    "                continue\n",
    "\n",
    "            query_docs_vec = []\n",
    "            query_docs_vec.append(doc2vec[query])\n",
    "            docs_vec = []\n",
    "            for doc in docs:\n",
    "                docs_vec.append(doc2vec[doc])\n",
    "\n",
    "            # gen episode\n",
    "            rank_list = self.gen_group_episode_greedy(query_docs_vec, docs_vec, docs, truth[query])\n",
    "\n",
    "            the_alphaNDCG = alphaNDCG_per_query(rank_list, truth[query])\n",
    "            mean_alphaNDCG += np.asarray(the_alphaNDCG)\n",
    "            # print reward[0],\n",
    "        mean_alphaNDCG = mean_alphaNDCG / n_query\n",
    "        print '\\n\\t\\t', mean_alphaNDCG.tolist()\n",
    "\n",
    "\n",
    "    def train_model(self, querydocs, doc2vec, truth):\n",
    "        querylist = querydocs.keys()\n",
    "        train_data = {}\n",
    "\n",
    "        mean_reward = 0\n",
    "        nquery = len(querylist)\n",
    "        for query in querylist:\n",
    "            docs = querydocs[query][:]\n",
    "\n",
    "            querydocsvec = []\n",
    "            querydocsvec.append(doc2vec[query])\n",
    "            docsvec = []\n",
    "            for doc in docs:\n",
    "                docsvec.append(doc2vec[doc])\n",
    "\n",
    "            # print 'gen_episode_softmax'\n",
    "            ranklist, querydocvec, feedback = self.gen_group_episode_softmax(querydocsvec, docsvec, docs, truth[query])\n",
    "            # print ranklist\n",
    "            reward = alphaDCG_group_reward_per_query(ranklist, truth[query])\n",
    "            mean_reward += reward[0]\n",
    "            # print 'reward', reward[0]\n",
    "            train_data[query] = {'querydocvec': querydocvec, 'reward': reward, 'feedback': feedback}\n",
    "        mean_reward = mean_reward / nquery\n",
    "        print mean_reward,\n",
    "\n",
    "        for query in querylist:\n",
    "            querydocvec = train_data[query]['querydocvec']\n",
    "            reward = train_data[query]['reward']\n",
    "            feedback = train_data[query]['feedback']\n",
    "            self.optimize_model(querydocvec, feedback, reward)\n",
    "\n",
    "    def optimize_model(self, querydocvec, relevance_feedback, reward):\n",
    "        ndoc = len(querydocvec)\n",
    "        input = [querydocvec[0]]\n",
    "        for time in range(len(reward)):\n",
    "            if reward[time] == 0:\n",
    "                continue\n",
    "            for i in range(self.group_size):\n",
    "                sess.run(train_step, feed_dict={query_docs: np.asanyarray(input), candidate_docs: np.asanyarray(querydocvec[time*self.group_size + i:ndoc + 1]), learning_rate: self.lr * reward[i]})\n",
    "\n",
    "            input += relevance_feedback[time]\n",
    "\n",
    "    def main(self, nite, querydocs, doc2vec, query_document_topic):\n",
    "        for ite in range(nite):\n",
    "            self.train_model(querydocs, doc2vec, query_document_topic)\n",
    "\n",
    "            if ite % 10 == 0:\n",
    "                self.test_model(querydocs, doc2vec, query_document_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1\nload 2\nload 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 4\n"
     ]
    }
   ],
   "source": [
    "Truth = json.load(open('/home/zw/DD/data/Truth.json'))\n",
    "print 'load 1'\n",
    "IdQuery = json.load(open('/home/zw/DD/data/IdQuery.json'))\n",
    "print 'load 2'\n",
    "QueryDocs = json.load(open('/home/zw/DD/data/QueryDocs.json'))\n",
    "print 'load 3'\n",
    "Doc2Vec = yaml.load(open('/home/zw/DD/data/Doc2Vec.yml'))\n",
    "print 'load 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DDRank_1' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f2c6485ca5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDRank_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLenepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DDRank_1' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "Nfeature=200\n",
    "Nhidden = 10\n",
    "Lenepisode = 10\n",
    "lr=0.1\n",
    "\n",
    "model = DDRank_1(Lenepisode, Nfeature, Nhidden, lr)\n",
    "\n",
    "\n",
    "model.main(10000, QueryDocs, Doc2Vec, Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}